{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkATQPymHRYY"
      },
      "source": [
        "# Part 2: Cloud VAME Project without GPU "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efLPfO0CH-qY"
      },
      "source": [
        "Note: Open this jupyter notebook in GoogleColab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzl2tC2nOWUv"
      },
      "source": [
        "## GoogleColab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDBICf3qOcoI",
        "outputId": "636aec8d-b889-44d1-ac11-0fb4f9e23a5e"
      },
      "outputs": [],
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEBHIxfmP5nV"
      },
      "source": [
        "Open Google Drive in separate tab for better overview of directory structure: \n",
        "https://drive.google.com/drive/my-drive\n",
        "\n",
        "Click on Runtime > Change runtime type and select GPU hardware acceleration. Check access to your GPU with the command below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFs79abpROo4",
        "outputId": "acf5190a-5d73-4865-f302-3b238c1d7620"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hPDx2ZuQqz0"
      },
      "outputs": [],
      "source": [
        "# Import some packages ...\n",
        "import pip\n",
        "import jupyter\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v24pF3jeOvjF"
      },
      "outputs": [],
      "source": [
        "# Install more packages ...\n",
        "!pip install pytest-shutil\n",
        "!pip install scipy\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install pathlib\n",
        "!pip install pandas\n",
        "!pip install ruamel.yaml\n",
        "!pip install sklearn\n",
        "!pip install pyyaml\n",
        "!pip install opencv-python-headless\n",
        "!pip install h5py\n",
        "!pip install umap\n",
        "!pip install umap-learn\n",
        "!pip install networkx\n",
        "!pip install tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dphTbr-ZP_Xo"
      },
      "outputs": [],
      "source": [
        "# check pip installed packages\n",
        "# !pip list -v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_chohuPIIKWD"
      },
      "source": [
        "## Download and Install VAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNTVJls6WHmL"
      },
      "outputs": [],
      "source": [
        "# Download VAME\n",
        "!git clone https://github.com/LINCellularNeuroscience/VAME.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3-HSqYCHlnH"
      },
      "outputs": [],
      "source": [
        "%cd /content/VAME\n",
        "!python setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdYcWL5kVCWD"
      },
      "outputs": [],
      "source": [
        "import vame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVxOhbozWbaM"
      },
      "source": [
        "## Download VAME Example Data \n",
        "Download `video-1.csv` and `video-1.mp4` from here: https://drive.google.com/drive/folders/1feCukw2H0teLvaPbwelhD2E2ns_viHFX?usp=sharing and save it to your own Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3KxH6dsIx_Z"
      },
      "source": [
        "## Step 1: Create a new VAME project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU2ec0jhHTiO"
      },
      "outputs": [],
      "source": [
        "project = 'NewVAMEProject_20211201'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb9toQ1iI1WG"
      },
      "outputs": [],
      "source": [
        "working_directory = '/content/drive/MyDrive/VAME_Example'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sd1HzctaI2m9"
      },
      "outputs": [],
      "source": [
        "videos = '/content/drive/MyDrive/VAME_Example/video-1.mp4'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB7r8yf_Mjks"
      },
      "source": [
        "### Step 1.1: Initiazile a VAME Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLp6DNjWJPoU"
      },
      "source": [
        "With the variables above, initialize a new project and save the path to the `config.yaml` file as `config`. This will create a new project folder with a predefined structure in your working_directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCMTqY1lJe4s",
        "outputId": "3894174f-84e2-4357-bce1-ba0b135c72ea"
      },
      "outputs": [],
      "source": [
        "config = vame.init_new_project(project=project, videos=videos, working_directory=working_directory, videotype='.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dXt7uQVIczx"
      },
      "source": [
        "Alternatively, you can open an existing VAME project by linking to the existing `config.yaml` file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwUqsUXyJtP3"
      },
      "outputs": [],
      "source": [
        "config = '/YOUR/WORKING/DIRECTORY/NewVAMEProject_20211201/config.yaml'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaMxCPStKbuy"
      },
      "source": [
        "### Step 1.2: Get your data ready"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6PlzM6tZ4Mb"
      },
      "source": [
        "First, move your DeepLabCut `.csv` data to the corresponding `videos/pose_estimation/` directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWaq-db7Kk8v"
      },
      "source": [
        "Then, use the function below to align your behavior videos egocentrically given `pose_ref_index` as a list of reference coordinate for alignment. In this case `[0,5]`. Example: 0: snout, 1: forehand_left, 2: forehand_right, 3: hindleft, 4: hindright, 5: tail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpiDx-pWKQ4U",
        "outputId": "900fc2ca-c8da-47d4-fb84-264b6b06c2e1"
      },
      "outputs": [],
      "source": [
        "vame.egocentric_alignment(config, pose_ref_index=[0,5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fySdbusUK72k"
      },
      "source": [
        "Alternatively, if your data is already egocentrically aligned, or you don't really believe that behavior should be studied egocentrically, transform your DeepLabCut `.csv` files to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbfmoYmbKIao"
      },
      "outputs": [],
      "source": [
        "vame.csv_to_numpy(config, datapath='C:\\\\Research\\\\VAME\\\\vame_alpha_release-Mar16-2021\\\\videos\\\\pose_estimation\\\\')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2HUfDmLLgey"
      },
      "source": [
        "### Step 1.3: Create the Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2p9W4OGKwLz",
        "outputId": "1f4a97bb-5bc3-42da-e08f-f4f0f0585402"
      },
      "outputs": [],
      "source": [
        "vame.create_trainset(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQUT9FL0Lt6m"
      },
      "source": [
        "## Step 2: Train your VAME Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKLdsPyVKwJB",
        "outputId": "d48bcd03-ac97-4fcc-e255-8c46ec2e7874"
      },
      "outputs": [],
      "source": [
        "vame.train_model(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFQGvpk-MN1m"
      },
      "source": [
        "## Step 3: Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVpcQqlDMTN-"
      },
      "outputs": [],
      "source": [
        "vame.evaluate_model(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9G05wOZMV4H"
      },
      "source": [
        "## Step 4: Motif segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cl8l-YEjMTLb"
      },
      "outputs": [],
      "source": [
        "vame.pose_segmentation(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTglg1eWMuE3"
      },
      "source": [
        "## Step 5: Create Motif Videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK3I7rpoMTJK"
      },
      "outputs": [],
      "source": [
        "vame.motif_videos(config, videoType='.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkvJ55cxMzk6"
      },
      "source": [
        "## Step 6: Create behavioral hierarchies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHfmLLilMS-_"
      },
      "outputs": [],
      "source": [
        "vame.community(config, show_umap=False, cut_tree=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp4knDFYM5iL"
      },
      "source": [
        "## Step 7: Create community videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObWumIxMM9Rc"
      },
      "outputs": [],
      "source": [
        "vame.community_videos(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BPgS_nnNAjJ"
      },
      "source": [
        "## Step 8: Create UMAP visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6Qv5-nMM9WW"
      },
      "outputs": [],
      "source": [
        "vame.visualization(config, label=None) #options: label: None, \"motif\", \"community\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6r4ShAKNI8P"
      },
      "source": [
        "## Step 9: Create GIF Animation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk3AVWweNIHn"
      },
      "outputs": [],
      "source": [
        "# Note: This function is currently very slow. Once the frames are saved you can create a video\n",
        "# or gif via e.g. ImageJ or other tools\n",
        "vame.gif(config, pose_ref_index=[0,5], subtract_background=True, start=None, \n",
        "         length=500, max_lag=30, label='community', file_format='.mp4', crop_size=(300,300))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phMpvngINZ60"
      },
      "source": [
        "## Step 10: Create a generative model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41Ty2RfzNIE7"
      },
      "outputs": [],
      "source": [
        "vame.generative_model(config, mode=\"centers\") #options: mode: \"sampling\", \"reconstruction\", \"centers\", \"motifs\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Part2VAME.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
