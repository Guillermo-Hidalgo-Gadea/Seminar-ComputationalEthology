{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Analysis in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will take a look at 3D coordinates of a short facial expression sequence.  \n",
    "We will learn to work with csv data in python with pandas and numpy, create plots with matplotlib and to sequence time series data with Hidden Markov Models. \n",
    "\n",
    "This exercise is based on two blogpost with tips and tricks to [analyze facial expression](https://guillermohidalgogadea.com/openlabnotebook/upgrade-your-next-zoom-meeting/) and useful tips to [write clean python code](https://guillermohidalgogadea.com/openlabnotebook/how-to-keep-your-python-code-tidy-with-4-easy-tips/). Follow the links for further information.  \n",
    "\n",
    "Please download the .ipynb file and follow along on your computer. Add markdown blocks with notes and comments taken during the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this exercise is provided [here](https://ruhr-uni-bochum.sciebo.de/s/vbPMqaYCcUjWA34). A short sequence of facial expressions was recorded with two synchronized cameras, tracked with DeepLabCut and triangulated with Anipose for 3D analysis. See the videos below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe width=\"400\" height = \"200\" src=\"https://www.youtube.com/embed/MZmbhE77eWo\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "<iframe width=\"400\" height = \"200\" src=\"https://www.youtube.com/embed/JaR1tO0EBnU\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To play the videos in Jupyter Notebook run this cell\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"965\" height=\"475\" src=\"https://www.youtube.com/embed/MZmbhE77eWo\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')\n",
    "HTML('<iframe width=\"965\" height=\"475\" src=\"https://www.youtube.com/embed/JaR1tO0EBnU\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Conda Environments\n",
    "\n",
    "```conda create --name analysis```  \n",
    "```conda activate analysis```  \n",
    "```conda install ipython jupyterlab pandas numpy tk matplotlib```  \n",
    "```pip install hmmlearn```  \n",
    "  \n",
    "```conda deactivate```   \n",
    "```conda remove --name analysis --all```  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the libraries you will need to have installed in your environment\n",
    "\n",
    "import math\n",
    "import tkinter.filedialog\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us start the analysis by loading the csv file from the pose-3d output of Anipose\n",
    "file = tkinter.filedialog.askopenfile(title='Select the csv file in the pose-3d directory', mode=\"r\")\n",
    "data = pd.read_csv(file, header=0)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apart from the x-, y-, z-coordinates we are interested in, the anipose output also contains other variables we want to discard for now\n",
    "scores = data.loc[:, data.columns.str.contains('score')]\n",
    "scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = data.loc[:, data.columns.str.contains('error')]\n",
    "errors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's filter the coordinates and ignore the other variables\n",
    "coords = data.loc[:,~data.columns.str.contains('score|error|ncams|fnum|center|M_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Egocentric Alignement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to define facial expressions in egocentric coordinates relative to the nasal bone \n",
    "# Note that the reference point is arbitrary, but the nasal bone is a great reference, as it moves only by head movements and not by facial expressions.\n",
    "centered_coords = coords.copy()\n",
    "for i in range(centered_coords.shape[1]):\n",
    "    if '_x' in centered_coords.columns[i]:\n",
    "        centered_coords.loc[:,centered_coords.columns[i]] = centered_coords.loc[:,centered_coords.columns[i]].subtract(coords.loc[:,\"nose1_x\"].values)\n",
    "    elif '_y' in centered_coords.columns[i]:\n",
    "        centered_coords.loc[:,centered_coords.columns[i]] = centered_coords.loc[:,centered_coords.columns[i]].subtract(coords.loc[:,\"nose1_y\"].values)\n",
    "    elif '_z' in centered_coords.columns[i]:\n",
    "        centered_coords.loc[:,centered_coords.columns[i]] = centered_coords.loc[:,centered_coords.columns[i]].subtract(coords.loc[:,\"nose1_z\"].values)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoface_egocentric = centered_coords.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kinematic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additionally to the relative coordinates for facial expression, we also may want to calculate some useful features of head movement\n",
    "features = centered_coords.copy()\n",
    "\n",
    "# Head position as coordinates of nasal bone reference\n",
    "features['position_x'] = coords['nose1_x']\n",
    "features['position_y'] = coords['nose1_y']\n",
    "features['position_z'] = coords['nose1_z']\n",
    "\n",
    "pos_x, = plt.plot(features['position_x'], label='x')\n",
    "pos_y, = plt.plot(features['position_y'], label='y')\n",
    "pos_z, = plt.plot(features['position_z'], label='z')\n",
    "plt.xlabel('Time [frames]')\n",
    "plt.ylabel('Position [pixel]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Velocity of head movement as frame-to-frame difference in position\n",
    "features['velocity_x'] = np.append([0],np.diff(features['position_x'], n=1)) \n",
    "features['velocity_y'] = np.append([0],np.diff(features['position_y'], n=1))\n",
    "features['velocity_z'] = np.append([0],np.diff(features['position_z'], n=1))\n",
    "\n",
    "vel_x, = plt.plot(features['velocity_x'], label='x')\n",
    "vel_y, = plt.plot(features['velocity_y'], label='y')\n",
    "vel_z, = plt.plot(features['velocity_z'], label='z')\n",
    "plt.xlabel('Time [frames]')\n",
    "plt.ylabel('Velocity [pixel/s]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceleration of head movement as frame-to-frame difference in velocity\n",
    "features['acceleration_x'] = np.append([0],np.diff(features['velocity_x'], n=1))\n",
    "features['acceleration_y'] = np.append([0],np.diff(features['velocity_y'], n=1))\n",
    "features['acceleration_z'] = np.append([0],np.diff(features['velocity_z'], n=1))\n",
    "\n",
    "acc_x, = plt.plot(features['acceleration_x'], label='x')\n",
    "acc_y, = plt.plot(features['acceleration_y'], label='y')\n",
    "acc_z, = plt.plot(features['acceleration_z'], label='z')\n",
    "plt.xlabel('Time [frames]')\n",
    "plt.ylabel('Acceleration [pixel/s^2]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can train a Hidden markov Model with our features (centered corrdinates, head position, velocity and acceleration)\n",
    "model1 = hmm.GaussianHMM(n_components = 9, covariance_type=\"full\") # change the number of components you expect to find in your data\n",
    "model1.fit(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model1.predict(features)\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition1 = model1.transmat_\n",
    "transition1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means1 = model1.means_\n",
    "means1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we may want to exclude head movement at all and train our HMM with facial expression only\n",
    "model2 = hmm.GaussianHMM(n_components = 9, covariance_type=\"full\" )# change the number of components you expect to find in your data\n",
    "model2.fit(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model2.predict(coords)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition2 = model2.transmat_\n",
    "transition2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means2 = model2.means_\n",
    "means2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To better see what just happend we can plot the time series segmentation by HMM predictions\n",
    "def plot_prediction(data, predictions):\n",
    "    \"\"\"\n",
    "    This function will plot the time series data and mark the transitions between predicted classes.\n",
    "    \n",
    "    \"\"\"\n",
    "    colors = {\"0\": \"black\", \"1\":\"dimgray\", \"2\":\"darkgray\", \"3\":\"white\", \"4\":\"bisque\", \"5\":\"tan\", \"6\":\"orange\", \"7\":\"salmon\", \"8\":\"gold\", \"9\":\"rosybrown\", \"10\":\"beige\", \"11\":\"thistle\", \"12\":\"peachpuff\", \"13\":\"khaki\", \"14\":\"skyblue\", \"15\":\"lightblue\", \"16\":\"lightsteelblue\", \"17\":\"lavender\", \"18\":\"mediumaquamarine\", \"19\":\"cadetblue\"}\n",
    "    n = max(predictions)+1\n",
    "    name =[x for x in globals() if globals()[x] is data][0]\n",
    "    yloc = max(np.max(data))-(max(np.max(data)) - min(np.min(data)))/8\n",
    "    locy = yloc - (max(np.max(data)) - min(np.min(data)))/8\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    ax.plot(data)\n",
    "    start_pred = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if i == len(predictions)-1:\n",
    "            end_pred = i+1\n",
    "            ax.axvspan(start_pred,end_pred, facecolor=colors[\"%d\" %predictions[i]], alpha = 0.5)\n",
    "            loc = start_pred + (end_pred - start_pred)/2\n",
    "            ax.annotate('%d'%predictions[i], xy=(loc, locy), xytext=(loc+10, yloc),\n",
    "            arrowprops=dict(arrowstyle=\"->\", facecolor='black'))\n",
    "        elif predictions[i] == predictions[i+1]:\n",
    "            pass\n",
    "        else:\n",
    "            end_pred = i\n",
    "            ax.axvspan(start_pred,end_pred, facecolor=colors[\"%d\" %predictions[i]], alpha = 0.5)\n",
    "            loc = start_pred + (end_pred - start_pred)/2\n",
    "            ax.annotate('%d'%predictions[i], xy=(loc, locy), xytext=(loc+10, yloc),\n",
    "            arrowprops=dict(arrowstyle=\"->\", facecolor='black'))\n",
    "            start_pred = end_pred\n",
    "        \n",
    "    plt.xlabel(\"Time [frames]\")\n",
    "    plt.ylabel(\"Feature value from %s data\" %name)\n",
    "    plt.title('Hidden Markov Model predictions with N = %d Components' %n)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(features, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(coords, pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we will spit the entire time series of our video into each predicted class and calculate the average pose during that segment\n",
    "def split_data(data, prediction):\n",
    "    \"\"\"\n",
    "    The split_data function will be used to split time series data into smaller \n",
    "    chunks by the prediction variable.\n",
    "    \n",
    "    \"\"\"\n",
    "    n = max(prediction)+1 #read out the number of predicted components\n",
    "    data['pred'] = prediction\n",
    "    grouped = data.groupby(data.pred)\n",
    "    predictions = [grouped.get_group(i) for i in range(n)]\n",
    "    pose = [predictions[i].mean() for i in range(n)]\n",
    "    \n",
    "    return predictions, pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1, pose1 = split_data(centered_coords, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2, pose2 = split_data(centered_coords, pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to have a look at the average pose durig each predicted class. Because the facial landmarks alone would look a bit sad, we start by defining a facial skeleton to connect coordinates\n",
    "\n",
    "def face_skeleton(pose):\n",
    "    \"\"\"\n",
    "    The face_skeleton function defines a mesh skeleton by connecting the facial landmarks as defined below.\n",
    "    This function is directly passed to plot_3Dpose. \n",
    "    \"\"\"\n",
    "    skeletons = []\n",
    "    for n in range(len(pose)): # read out n_components from different poses\n",
    "    \n",
    "        lefteye = [pose[n]['lefteye1_x'], pose[n]['lefteye2_x']], [pose[n]['lefteye1_y'], pose[n]['lefteye2_y']], [pose[n]['lefteye1_z'], pose[n]['lefteye2_z']]\n",
    "        righteye = [pose[n]['righteye1_x'], pose[n]['righteye2_x']], [pose[n]['righteye1_y'], pose[n]['righteye2_y']], [pose[n]['righteye1_z'], pose[n]['righteye2_z']]\n",
    "        leyebrow = [pose[n]['leyebrow1_x'], pose[n]['leyebrow2_x'],pose[n]['leyebrow3_x']],[pose[n]['leyebrow1_y'], pose[n]['leyebrow2_y'],pose[n]['leyebrow3_y']],[pose[n]['leyebrow1_z'], pose[n]['leyebrow2_z'],pose[n]['leyebrow3_z']]\n",
    "        reyebrow = [pose[n]['reyebrow1_x'], pose[n]['reyebrow2_x'],pose[n]['reyebrow3_x']],[pose[n]['reyebrow1_y'], pose[n]['reyebrow2_y'],pose[n]['reyebrow3_y']],[pose[n]['reyebrow1_z'], pose[n]['reyebrow2_z'],pose[n]['reyebrow3_z']]\n",
    "        nose = [pose[n]['nose1_x'],pose[n]['nose3_x'],pose[n]['nose2_x'],pose[n]['nose4_x'],pose[n]['nose1_x']],[pose[n]['nose1_y'],pose[n]['nose3_y'],pose[n]['nose2_y'],pose[n]['nose4_y'],pose[n]['nose1_y']],[pose[n]['nose1_z'],pose[n]['nose3_z'],pose[n]['nose2_z'],pose[n]['nose4_z'],pose[n]['nose1_z']]\n",
    "        lips = [pose[n]['uplip_x'],pose[n]['llip_x'],pose[n]['lowlip_x'],pose[n]['rlip_x'],pose[n]['uplip_x']],[pose[n]['uplip_y'],pose[n]['llip_y'],pose[n]['lowlip_y'],pose[n]['rlip_y'],pose[n]['uplip_y']],[pose[n]['uplip_z'],pose[n]['llip_z'],pose[n]['lowlip_z'],pose[n]['rlip_z'],pose[n]['uplip_z']]\n",
    "        face = [pose[n]['rear_x'],pose[n]['chin_x'],pose[n]['lear_x']],[pose[n]['rear_y'],pose[n]['chin_y'],pose[n]['lear_y']],[pose[n]['rear_z'],pose[n]['chin_z'],pose[n]['lear_z']]\n",
    "        \n",
    "        skeleton = lefteye, righteye, leyebrow, reyebrow, nose, lips, face\n",
    "        skeletons.append(skeleton)\n",
    "    \n",
    "    return skeletons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3Dpose(pose, elevation, azimuth):\n",
    "    \"\"\"\n",
    "    This plot function takes the average pose coordinates of facial landmarks, creates a skeleton and visualizes the facial expression\n",
    "    in a 3D coordinate system with predefined elevantion and azimuth angles.\n",
    "    \"\"\"\n",
    "    skeletons = face_skeleton(pose)\n",
    "\n",
    "    ncols = 3\n",
    "    nrows = math.ceil(len(pose)/ncols)\n",
    "    width = ncols*6\n",
    "    height = nrows *5\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(width, height), subplot_kw=dict(projection='3d'))\n",
    "\n",
    "    for ax, n in zip(axes.flat, range(len(pose))):\n",
    "            x_points = pose[n][['_x' in s for s in pose[n].index]]\n",
    "            y_points = pose[n][['_y' in s for s in pose[n].index]]\n",
    "            z_points = pose[n][['_z' in s for s in pose[n].index]]\n",
    "            ax.scatter3D(x_points,y_points, z_points)\n",
    "            ax.view_init(elevation, azimuth)\n",
    "            ax.set(xlabel='X axis', ylabel='Y axis', zlabel='Z axis')\n",
    "            ax.set_title('Predicted Pose: %d' %(n+1))\n",
    "            for i in range(len(skeletons[0])):\n",
    "                x = skeletons[n][i][0]\n",
    "                y = skeletons[n][i][1]\n",
    "                z = skeletons[n][i][2]\n",
    "                ax.plot(x,y,z, color='g') \n",
    "                \n",
    "    plt.suptitle('Hidden Markov Model predictions with N = %d Components' %len(pose))\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3Dpose(pose1, 11, 280)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3Dpose(pose2, 11, 280)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we know how each facial expression looks like, we could analyze some simple kinematics to describe what actaually happens in each segment, appart from the average pose\n",
    "def plot_kinematics(predictions, pose):\n",
    "    \"\"\"\n",
    "    This Function will create multiple subplots for every predicted pose and visualize simple kinematics as line plot and histogram. \n",
    "    \n",
    "    \"\"\"\n",
    "    ncols = 3\n",
    "    nrows = math.ceil(len(predictions)/ncols)\n",
    "    width = ncols*6\n",
    "    height = nrows *5\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(width, height))\n",
    "\n",
    "    for ax, n in zip(axes.flat, range(len(pose))):\n",
    "        ax.plot(predictions[n]['position_x'], color = 'g', label = 'pos_x')\n",
    "        ax.plot(predictions[n]['position_y'], color = 'g', label = 'pos_y')\n",
    "        ax.plot(predictions[n]['position_z'], color = 'g', label = 'pos_z')\n",
    "        \n",
    "        ax.plot(predictions[n]['velocity_x'], color = 'y', label = 'vel_x')\n",
    "        ax.plot(predictions[n]['velocity_y'], color = 'y', label = 'vel_y')\n",
    "        ax.plot(predictions[n]['velocity_z'], color = 'y', label = 'vel_z')\n",
    "        \n",
    "        ax.plot(predictions[n]['acceleration_x'], color = 'r', label = 'acc_x')\n",
    "        ax.plot(predictions[n]['acceleration_y'], color = 'r', label = 'acc_y')\n",
    "        ax.plot(predictions[n]['acceleration_z'], color = 'r', label = 'acc_z')\n",
    "        \n",
    "        ax.set(xlabel='Time (frames)', ylabel='Position, Velocity and Acceleration')\n",
    "        ax.legend()\n",
    "        ax.set_title('Kinematic Profile in Predicted Class: %d' %n)\n",
    "                \n",
    "    plt.suptitle('Hidden Markov Model predictions with N = %d Components' %len(pose))\n",
    "    plt.show()\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(width, height))\n",
    "    \n",
    "    for ax, n in zip(axes.flat, range(len(pose))):\n",
    "        ax.hist(predictions[n]['position_x'], color = 'g', label = 'x')\n",
    "        ax.hist(predictions[n]['position_y'], color = 'y', label = 'y')\n",
    "        ax.hist(predictions[n]['position_z'], color = 'r', label = 'z')\n",
    "        \n",
    "        ax.set(xlabel='x, y, z movement', ylabel='frequency')\n",
    "        ax.legend()\n",
    "        ax.set_title('Movement in Predicted Class: %d' %n)\n",
    "                \n",
    "    plt.suptitle('Hidden Markov Model predictions with N = %d Components' %len(pose))\n",
    "    plt.show()\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(width, height))\n",
    "    \n",
    "    for ax, n in zip(axes.flat, range(len(pose))):\n",
    "        ax.hist(predictions[n]['velocity_x'], color = 'g', label = 'x')\n",
    "        ax.hist(predictions[n]['velocity_y'], color = 'y', label = 'y')\n",
    "        ax.hist(predictions[n]['velocity_z'], color = 'r', label = 'z')\n",
    "        \n",
    "        ax.set(xlabel='x, y, z velocity', ylabel='frequency')\n",
    "        ax.legend()\n",
    "        ax.set_title('Velocity in Predicted Class: %d' %n)\n",
    "                \n",
    "    plt.suptitle('Hidden Markov Model predictions with N = %d Components' %len(pose))\n",
    "    plt.show()\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(width, height))\n",
    "    \n",
    "    for ax, n in zip(axes.flat, range(len(pose))):\n",
    "        ax.hist(predictions[n]['acceleration_x'], color = 'g', label = 'x')\n",
    "        ax.hist(predictions[n]['acceleration_y'], color = 'y', label = 'y')\n",
    "        ax.hist(predictions[n]['acceleration_z'], color = 'r', label = 'z')\n",
    "        \n",
    "        ax.set(xlabel='x, y, z acceleration', ylabel='frequency')\n",
    "        ax.legend()\n",
    "        ax.set_title('Acceleration in Predicted Class: %d' %n)\n",
    "                \n",
    "    plt.suptitle('Hidden Markov Model predictions with N = %d Components' %len(pose))\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1, pose1 = split_data(features, pred1)\n",
    "\n",
    "plot_kinematics(predictions1, pose1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2, pose2 = split_data(features, pred2)\n",
    "\n",
    "plot_kinematics(predictions2, pose2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}